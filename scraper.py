import os
import feedparser
import re
import random
from supabase import create_client
from googleapiclient.discovery import build

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø¨Ø· - ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ù…ÙŠØ§Øª ÙÙŠ GitHub Secrets
URL = os.getenv("SUPABASE_URL")
KEY = os.getenv("SUPABASE_KEY")  # ÙŠÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… service_role key Ù‡Ù†Ø§
YT_KEY = os.getenv("YOUTUBE_API_KEY")

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡
try:
    supabase = create_client(URL, KEY)
    youtube = build('youtube', 'v3', developerKey=YT_KEY)
except Exception as e:
    print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©: {e}")

def get_fixed_images():
    images = [
        "https://images.unsplash.com/photo-1461749280684-dccba630e2f6?w=800",
        "https://images.unsplash.com/photo-1498050108023-c5249f4df085?w=800",
        "https://images.unsplash.com/photo-1587620962725-abab7fe55159?w=800"
    ]
    random.shuffle(images)
    return images

def start_news_scraping():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø³Ø­Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
    sources = [
        {"url": "https://aitnews.com/category/Ø¨Ø±Ù…Ø¬ÙŠØ§Øª-ÙˆØ¹Ù„ÙˆÙ…-Ø­Ø§Ø³Ø¨/feed/", "cat": "Ø¨Ø±Ù…Ø¬ÙŠØ§Øª"},
        {"url": "https://www.tech-wd.com/wd/category/programming/feed/", "cat": "Ø¨Ø±Ù…Ø¬Ø©"}
    ]
    img_pool = get_fixed_images()
    
    for source in sources:
        feed = feedparser.parse(source['url'])
        for entry in feed.entries[:5]:
            news_data = {
                "title": entry.title,
                "image_url": random.choice(img_pool),
                "content": entry.summary[:250] if 'summary' in entry else entry.title,
                "author": "Ù…ØµØ¯Ø± ØªÙ‚Ù†ÙŠ",
                "category": source['cat']
            }
            try:
                supabase.table("academy_news").upsert(news_data, on_conflict='title').execute()
            except Exception as e:
                print(f"âš ï¸ ÙØ´Ù„ Ø±ÙØ¹ Ø®Ø¨Ø±: {e}")
    print("âœ… Ø§ÙƒØªÙ…Ù„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø®Ø¨Ø§Ø±.")

def sync_lessons():
    print("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒÙˆØ±Ø³Ø§Øª ÙˆØ§Ù„Ø¯Ø±ÙˆØ³...")
    
    # Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ÙƒÙˆØ±Ø³Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ Foreign Key
    courses_data = [
        {"id": 1, "title": "CS50 - Ø¹Ù„ÙˆÙ… Ø§Ù„Ø­Ø§Ø³Ø¨"},
        {"id": 2, "title": "Flutter - ØªØ·Ø¨ÙŠÙ‚Ø§Øª"},
        {"id": 3, "title": "Python - Ù„ØºØ© Ø¨Ø§ÙŠØ«ÙˆÙ†"}
    ]
    try:
        supabase.table("courses").upsert(courses_data).execute()
    except Exception as e:
        print(f"âš ï¸ ØªÙ†Ø¨ÙŠÙ‡: Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙƒÙˆØ±Ø³Ø§ØªØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† RLS Ù…ÙØ¹Ù„Ø§Ù‹: {e}")

    playlists = [
        ("PLDoPjvoNmBAw6p0z0Ek0OjPzeXoqlL72x", 1),
        ("PL4cUxeGkcC9jLYyp2Aoh6suWpFDbR6E_v", 2),
        ("PLu0W_9lII9agICnT8t4iYVSZ3EnUNzXRm", 3)
    ]

    for p_id, c_id in playlists:
        try:
            request = youtube.playlistItems().list(part='snippet', playlistId=p_id, maxResults=20)
            response = request.execute()
            
            lessons = []
            for item in response.get('items', []):
                lessons.append({
                    "course_id": c_id,
                    "title": item['snippet']['title'],
                    "video_url": f"https://www.youtube.com/watch?v={item['snippet']['resourceId']['videoId']}",
                    "order_index": item['snippet']['position'] + 1
                })
            
            if lessons:
                supabase.table("lessons").upsert(lessons, on_conflict='video_url').execute()
                print(f"âœ… ØªÙ… Ø±ÙØ¹ {len(lessons)} Ø¯Ø±Ø³ Ù„Ù„ÙƒÙˆØ±Ø³ {c_id}")
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø­Ù‚ÙŠÙ‚ÙŠ ÙÙŠ Ø§Ù„ÙƒÙˆØ±Ø³ {c_id}: {str(e)}")

if __name__ == "__main__":
    start_news_scraping()
    sync_lessons()
    print("ğŸ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©.")
