import os
import feedparser
from supabase import create_client

# Ø±Ø¨Ø· Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø§Ù„Ø®Ø²Ù†Ø©
URL = os.getenv("SUPABASE_URL")
KEY = os.getenv("SUPABASE_KEY")
supabase = create_client(URL, KEY)

def start_scraping():
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (RSS) - Ø¯ÙŠ Ø£Ø³Ø±Ø¹ ÙˆØ³ÙŠÙ„Ø© ØªØ¬ÙŠØ¨ Ø£Ø®Ø¨Ø§Ø± ÙƒØªÙŠØ±
    sources = [
        "https://aitnews.com/feed/",
        "https://www.tech-wd.com/wd/feed/",
        "https://www.unlimit-tech.com/feed/"
    ]
    
    print("ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
    for url in sources:
        feed = feedparser.parse(url)
        for entry in feed.entries[:20]:  # Ù‡ÙŠØ³Ø­Ø¨ 20 Ø®Ø¨Ø± Ù…Ù† ÙƒÙ„ Ù…ÙˆÙ‚Ø¹
            news_data = {
                "title": entry.title,
                "image_url": "https://img.freepik.com/free-vector/breaking-news-concept_23-2148514216.jpg",
                "content": f"Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„: {entry.link}"
            }
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø®Ø¨Ø± (ÙˆÙ„Ùˆ Ù…ÙˆØ¬ÙˆØ¯ Ù‚Ø¨Ù„ ÙƒØ¯Ø© Ù‡ÙŠØ¹Ù…Ù„ Ù„Ù‡ ØªØ­Ø¯ÙŠØ« Ù…Ø´ ØªÙƒØ±Ø§Ø±)
            try:
                supabase.table("academy_news").upsert(news_data, on_conflict='title').execute()
            except:
                continue
    print("âœ… Ø®Ù„ØµØª! Ø±ÙˆØ­ Ø´ÙˆÙ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø¯Ù„ÙˆÙ‚ØªÙŠ.")

if __name__ == "__main__":
    start_scraping()
